{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from itertools import groupby\n",
    "import re\n",
    "\n",
    "import Overall_HMM_helper\n",
    "from Naive_HMM import unsupervised_HMM\n",
    "import Naive_HMM_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of poems: 154\n",
      "Sonnets 98 and 125 are not 14 lines long so we remove them from our list.\n",
      "Final number of poems: 152\n"
     ]
    }
   ],
   "source": [
    "shakespeare = open(\"data/shakespeare.txt\", 'r')\n",
    "\n",
    "poems = shakespeare.readlines()\n",
    "split_at = \"\\n\"\n",
    "final_poems = [list(g)[1:] for k, g in groupby(poems, lambda x: x != split_at) if k]\n",
    "print(\"Initial number of poems: {}\".format(len(final_poems)))\n",
    "poem_lengths = [len(poem) for poem in final_poems] \n",
    "bad_poems = np.where(np.array(poem_lengths)!= 14)[0]\n",
    "print (\"Sonnets {} and {} are not 14 lines long so we remove them from our list.\".format(bad_poems[0], bad_poems[1]))\n",
    "\n",
    "final_poems = [final_poems[i] for i in np.delete(np.arange(len(final_poems)), bad_poems)]\n",
    "print(\"Final number of poems: {}\".format(len(final_poems)))\n",
    "final_poems = [''.join([line.strip(' ') for line in poem]) for poem in final_poems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# token_map maps words to numbers\n",
    "# tokenized_poems replaces the words in poems with their corresponding number\n",
    "tokenized_poems, token_map = Overall_HMM_helper.parse_observations(final_poems)\n",
    "token_map_r = Overall_HMM_helper.obs_map_reverser(token_map)\n",
    "flattened_tokenized_poems = [val for sublist in tokenized_poems for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helpful lists\n",
    "# Syllables\n",
    "syllable_file = open(\"data/Syllable_dictionary.txt\", 'r')\n",
    "syllables = syllable_file.readlines()\n",
    "syllables = [x.split() for x in syllables]\n",
    "syllable_dict = {}\n",
    "\n",
    "# We choose to map words to tuples of lists\n",
    "# the first list corresponds to the number of syllables if the word were at the end (E)\n",
    "# the second list corresponds to the number of syllables the word can take anywhere\n",
    "# E.g. \"test\": ['E1', '2', '3'] <-> \"test\": [([1], [2, 3])]\n",
    "for syllable in syllables:\n",
    "    word = re.sub(r'[^\\w]', '', syllable[0])\n",
    "    end_syllable_list = []\n",
    "    regular_syllable_list = []\n",
    "    for item in syllable[1:]:\n",
    "        if item[0] == \"E\":\n",
    "            end_syllable_list.append(int(item[1:]))\n",
    "        else:\n",
    "            regular_syllable_list.append(int(item))\n",
    "    syllable_dict[word] = (end_syllable_list, regular_syllable_list)\n",
    "    \n",
    "# syllable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_syllable_dict = {}\n",
    "for key in syllable_dict.keys():\n",
    "    # If the word in syllable_dict is in our token map, add it to our tokenized_syllable_dict\n",
    "    try:\n",
    "        tokenized_syllable_dict[token_map[key]] = syllable_dict[key]\n",
    "    except KeyError:\n",
    "        pass\n",
    "# tokenized_syllable_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllable Analysis - is in HMM_helper file (generate_emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deliberately do not make a 140 syllable line and then split them (which would allow for some extra continuity) because Shakespearean lines are typically treated as new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Naive Sonnet:\n",
      "====================\n",
      "Complexion but purging allayed my half;\n",
      "Admired shadow to thy what of once;\n",
      "One count proud of in keep soil one loving;\n",
      "Sweet i be end still is god and the fears;\n",
      "Thy well again amends bosoms sits so;\n",
      "Are love his that interest show all fear knows;\n",
      "But all fingers due anon gracious bids;\n",
      "Sea at thy side wrecked of motion love too;\n",
      "That eye and true and i am nothing eyes;\n",
      "Minds death hateth secret so upon in;\n",
      "Since eye picture less doth in if with be;\n",
      "Where time far to title but mind next break;\n",
      "Besmeared stays let the hold the mud so sun;\n",
      "And my tell his i blessedfair have thou;\n"
     ]
    }
   ],
   "source": [
    "# Flattens 3-dimensional list of list of lists to 2-dimensional list of lists\n",
    "# (where each inner list corresponds to a line of a poem)\n",
    "hmm = unsupervised_HMM(flattened_tokenized_poems, 2, 10, tokenized_syllable_dict)\n",
    "print('Naive Sonnet:\\n====================')\n",
    "for i in range(14):\n",
    "    print(Naive_HMM_helper.sample_sentence(hmm, token_map, num_syllables=10))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
